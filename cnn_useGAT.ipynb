{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8216f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 5090\n",
      "Memory Allocated: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Memory Allocated:\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9178d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch. utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from pymatgen.core import Structure, Element\n",
    "\n",
    "group_number = 18\n",
    "row_number = 7\n",
    "X_class_number = 10\n",
    "r_class_number = 10\n",
    "node_dim = group_number + row_number + X_class_number + r_class_number\n",
    "\n",
    "distance_class_number = 10\n",
    "edge_dim = distance_class_number\n",
    "\n",
    "learned_dim = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6f13a",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation\n",
    "\n",
    "- Use pymatgen to load the json_gz file and pretty print the content\n",
    "- Use Networkx to visualize the structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9726defb",
   "metadata": {},
   "source": [
    "\n",
    "## dataset\n",
    "\n",
    "- Input matrix should contains information about nodes and edges.\n",
    "- We only have element names, magnitude momentum of atoms, coordination of atoms to use:\n",
    "- we should compute the distance of nearest atoms to fullfill the edges matrix\n",
    "- for nodes information, use one-hot encoding to fullfill the nodes part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093e50ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor([-0.9775])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "path = './matbench_phonons.json/phonons.json'\n",
    "\n",
    "class DataTransform(Dataset):\n",
    "    def __init__(self, path, normalize = True):\n",
    "        super().__init__()\n",
    "        with open(path) as f:\n",
    "            obj = json.load(f)\n",
    "        self.index = obj[\"index\"]\n",
    "        self.data = obj[\"data\"]\n",
    "        max_index = max(self.index) + 1 if self.index else 0\n",
    "        self.struct_list = [None] * max_index    \n",
    "        for idx, data_item in zip(self.index, self.data):\n",
    "            self.struct_list[idx] = Structure.from_dict(data_item[0])\n",
    "        \n",
    "        self.normalize = normalize\n",
    "        if self.normalize:\n",
    "            all_labels = [self.data[idx][1] for idx in self.index]\n",
    "            self.label_mean = np.mean(all_labels)\n",
    "            self.label_std = np.std(all_labels)\n",
    "        else:\n",
    "            self.label_mean = 0.0\n",
    "            self.label_std = 1.0\n",
    "\n",
    "    def __len__(self):  # 必须实现\n",
    "        return len(self.index)\n",
    "    \n",
    "    def build_node(self, idx):\n",
    "        struct = self.struct_list[idx]\n",
    "        tensor_list = []\n",
    "        for site in struct.sites:\n",
    "            element = Element(site.specie.symbol)\n",
    "            radius = element.atomic_radius * 100  # convert to pm\n",
    "            # OneHot encoding with group and row:\n",
    "            group = element.group\n",
    "            row = element.row\n",
    "            X = element.X\n",
    "            # OneHot encoding with group and row:\n",
    "            group = F.one_hot(torch.tensor(group - 1), num_classes=18).float()\n",
    "            row = F.one_hot(torch.tensor(row - 1), num_classes=7).float()\n",
    "            if(25<=radius<250):\n",
    "                radius = F.one_hot(torch.tensor(int((radius - 25)/22.5)), num_classes=10).float()\n",
    "            else:\n",
    "                radius = torch.zeros(10)\n",
    "            if (X < 0.5 or X >= 4.0):\n",
    "                X =torch.zeros(10)\n",
    "            else:\n",
    "                X = F.one_hot(torch.tensor(int((X - 0.5) / 0.35)), num_classes=10).float()\n",
    "            # concate group and row features\n",
    "            node_feat = torch.cat([group, row, X, radius], dim=0)\n",
    "            # print(node_feats): \n",
    "            # tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # group 8\n",
    "            #         0, 0, 1, 0, 0, 0, 0,        # row 3\n",
    "            #         0, 0, 0, 0, 1, 0, 0, 0, 0, 0])          # X\n",
    "            \n",
    "            # concate group and row features \n",
    "            \n",
    "            tensor_list.append(node_feat)\n",
    "        node_feats = torch.stack(tensor_list, dim=0)\n",
    "        return node_feats\n",
    "    \n",
    "    def build_edge(self, idx, cutoff=5.0):\n",
    "        struct = self.struct_list[idx]\n",
    "        num_atoms = len(struct.sites)\n",
    "        nbrs = struct.get_all_neighbors(cutoff)\n",
    "        tensor_list = []\n",
    "        edge_index = torch.zeros((2,0), dtype=torch.long)\n",
    "        for center_idx, neighbors in enumerate(nbrs):\n",
    "            for neighbor in neighbors:\n",
    "                distance = neighbor.nn_distance\n",
    "                if (distance < 0.7 or distance >= 5.2):\n",
    "                    distance = torch.zeros(10)\n",
    "                else:\n",
    "                    distance = F.one_hot(torch.tensor(int((distance-0.7)/0.45)), num_classes=10).float()\n",
    "                tensor_list.append((distance))\n",
    "                edge_index = torch.cat([edge_index, torch.tensor([[center_idx],[neighbor.index]])], dim=1)\n",
    "            \n",
    "        edge_fea = torch.stack(tensor_list, dim=0)\n",
    "        return edge_index, edge_fea\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        node_fea = self.build_node(idx)\n",
    "        edge_index, edge_fea = self.build_edge(idx)\n",
    "        label = self.data[idx][1]\n",
    "        if self.normalize:\n",
    "            label = (label - self.label_mean) / self.label_std\n",
    "        y = torch.tensor([label], dtype=torch.float32)\n",
    "        data = Data(\n",
    "            x=node_fea,      \n",
    "            edge_index=edge_index, \n",
    "            edge_attr=edge_fea,\n",
    "            y=y\n",
    "        )\n",
    "        return data\n",
    "    \n",
    "'''    \n",
    "    def build_visualized_graph(self, idx, cutoff=5.0):\n",
    "        struct = self.struct_list[idx]\n",
    "        num_atoms = len(struct.sites)\n",
    "        G = nx.Graph()\n",
    "        for i in range(num_atoms):\n",
    "            G.add_node(i, element=struct.sites[i].specie.symbol)\n",
    "        nbrs = struct.get_all_neighbors(cutoff)\n",
    "        for center_idx, neighbors in enumerate(nbrs):\n",
    "            for neighbor in neighbors:\n",
    "                neighbor_idx = neighbor.index\n",
    "                if not G.has_edge(center_idx, neighbor_idx):\n",
    "                   G.add_edge(center_idx, neighbor_idx, distance=neighbor.nn_distance)\n",
    "        return G\n",
    "'''    \n",
    "\n",
    "try:\n",
    "    tryone = DataTransform(path)\n",
    "    \n",
    "    x, edge_index, edge_attr, y = tryone[0].x, tryone[0].edge_index, tryone[0].edge_attr, tryone[0].y\n",
    "    print(x)\n",
    "    print(edge_index)\n",
    "    print(edge_attr)\n",
    "    print(y)\n",
    "except Exception as e:\n",
    "    print(f\"运行出错：{e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fec9a",
   "metadata": {},
   "source": [
    "## Train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee4b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_data = DataTransform(path)\n",
    "\n",
    "train_size = int(0.8 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(\n",
    "    full_data, \n",
    "    [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # 固定随机种子\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03acb4",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3499267",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea2e6f",
   "metadata": {},
   "source": [
    "# Step 2: Model construction\n",
    "\n",
    "- Build the CGCNN model using multiple CGCNNLayer layers\n",
    "- Number of layers:\n",
    "- - GCNNNLayer: 2\n",
    "- - Fully connected layers: 2\n",
    "- - Pooling layer: global mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90758b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, TransformerConv\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 node_input_dim = node_dim,\n",
    "                 edge_input_dim = edge_dim,\n",
    "                 hidden_dim = 64,\n",
    "                 num_conv_layers = 4,\n",
    "                 dropout = 0.1\n",
    "                 ):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.node_embedding = nn.Sequential(\n",
    "            nn.Linear(node_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.edge_embedding = nn.Sequential(\n",
    "            nn.Linear(edge_input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            GATConv(\n",
    "                hidden_dim, \n",
    "                hidden_dim, \n",
    "                heads=4,  # 多头注意力\n",
    "                concat=False,\n",
    "                edge_dim=hidden_dim,\n",
    "                dropout=0.1\n",
    "            )\n",
    "            for _ in range(num_conv_layers)\n",
    "        ])\n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(hidden_dim) \n",
    "            for _ in range(num_conv_layers)\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        batch = data.batch  \n",
    "        x = self.node_embedding(x)\n",
    "        edge_attr = self.edge_embedding(edge_attr)\n",
    "        for conv, bn in zip(self.conv_layers, self.batch_norms):\n",
    "            identity = x\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = x + identity \n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Output Layer\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65783ccf",
   "metadata": {},
   "source": [
    "# Step 3: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56ad1e",
   "metadata": {},
   "source": [
    "## Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81fade61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在使用的设备: cuda\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"正在使用的设备: {device}\")\n",
    "model = model.to(device) \n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "criterion = criterion.to(device)  \n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b92440d",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "AI 说的，早停，减少过拟合/梯度消失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ad68741",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=20, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31a0bd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.7276\n",
      "Epoch [2/200], Loss: 0.3417\n",
      "Epoch [3/200], Loss: 0.2539\n",
      "Epoch [4/200], Loss: 0.2672\n",
      "Epoch [5/200], Loss: 0.2276\n",
      "Epoch [6/200], Loss: 0.1865\n",
      "Epoch [7/200], Loss: 0.1676\n",
      "Epoch [8/200], Loss: 0.1872\n",
      "Epoch [9/200], Loss: 0.1775\n",
      "Epoch [10/200], Loss: 0.1632\n",
      "Epoch [11/200], Loss: 0.1547\n",
      "Epoch [12/200], Loss: 0.1483\n",
      "Epoch [13/200], Loss: 0.1436\n",
      "Epoch [14/200], Loss: 0.1363\n",
      "Epoch [15/200], Loss: 0.1516\n",
      "Epoch [16/200], Loss: 0.1538\n",
      "Epoch [17/200], Loss: 0.1481\n",
      "Epoch [18/200], Loss: 0.1264\n",
      "Epoch [19/200], Loss: 0.1139\n",
      "Epoch [20/200], Loss: 0.0953\n",
      "Epoch [21/200], Loss: 0.1043\n",
      "Epoch [22/200], Loss: 0.1364\n",
      "Epoch [23/200], Loss: 0.1246\n",
      "Epoch [24/200], Loss: 0.1402\n",
      "Epoch [25/200], Loss: 0.1045\n",
      "Epoch [26/200], Loss: 0.1131\n",
      "Epoch [27/200], Loss: 0.0933\n",
      "Epoch [28/200], Loss: 0.1266\n",
      "Epoch [29/200], Loss: 0.1062\n",
      "Epoch [30/200], Loss: 0.1104\n",
      "Epoch [31/200], Loss: 0.1250\n",
      "Epoch [32/200], Loss: 0.1115\n",
      "Epoch [33/200], Loss: 0.0937\n",
      "Epoch [34/200], Loss: 0.1124\n",
      "Epoch [35/200], Loss: 0.0900\n",
      "Epoch [36/200], Loss: 0.0773\n",
      "Epoch [37/200], Loss: 0.0848\n",
      "Epoch [38/200], Loss: 0.0985\n",
      "Epoch [39/200], Loss: 0.0930\n",
      "Epoch [40/200], Loss: 0.0989\n",
      "Epoch [41/200], Loss: 0.0958\n",
      "Epoch [42/200], Loss: 0.0680\n",
      "Epoch [43/200], Loss: 0.0830\n",
      "Epoch [44/200], Loss: 0.0662\n",
      "Epoch [45/200], Loss: 0.0923\n",
      "Epoch [46/200], Loss: 0.0824\n",
      "Epoch [47/200], Loss: 0.0961\n",
      "Epoch [48/200], Loss: 0.0877\n",
      "Epoch [49/200], Loss: 0.0817\n",
      "Epoch [50/200], Loss: 0.0917\n",
      "Epoch [51/200], Loss: 0.0842\n",
      "Epoch [52/200], Loss: 0.0542\n",
      "Epoch [53/200], Loss: 0.0938\n",
      "Epoch [54/200], Loss: 0.0658\n",
      "Epoch [55/200], Loss: 0.0700\n",
      "Epoch [56/200], Loss: 0.0803\n",
      "Epoch [57/200], Loss: 0.0794\n",
      "Epoch [58/200], Loss: 0.0579\n",
      "Epoch [59/200], Loss: 0.0698\n",
      "Epoch [60/200], Loss: 0.0698\n",
      "Epoch [61/200], Loss: 0.0676\n",
      "Epoch [62/200], Loss: 0.0608\n",
      "Epoch [63/200], Loss: 0.0870\n",
      "Epoch [64/200], Loss: 0.0732\n",
      "Epoch [65/200], Loss: 0.0545\n",
      "Epoch [66/200], Loss: 0.0551\n",
      "Epoch [67/200], Loss: 0.0500\n",
      "Epoch [68/200], Loss: 0.0571\n",
      "Epoch [69/200], Loss: 0.0600\n",
      "Epoch [70/200], Loss: 0.0568\n",
      "Epoch [71/200], Loss: 0.0608\n",
      "Epoch [72/200], Loss: 0.0480\n",
      "Epoch [73/200], Loss: 0.0500\n",
      "Epoch [74/200], Loss: 0.0531\n",
      "Epoch [75/200], Loss: 0.0594\n",
      "Epoch [76/200], Loss: 0.0522\n",
      "Epoch [77/200], Loss: 0.0575\n",
      "Epoch [78/200], Loss: 0.0516\n",
      "Epoch [79/200], Loss: 0.0571\n",
      "Epoch [80/200], Loss: 0.0502\n",
      "Epoch [81/200], Loss: 0.0492\n",
      "Epoch [82/200], Loss: 0.0495\n",
      "Epoch [83/200], Loss: 0.0613\n",
      "Epoch [84/200], Loss: 0.0635\n",
      "Epoch [85/200], Loss: 0.0631\n",
      "Epoch [86/200], Loss: 0.0660\n",
      "Epoch [87/200], Loss: 0.0369\n",
      "Epoch [88/200], Loss: 0.0495\n",
      "Epoch [89/200], Loss: 0.0648\n",
      "Epoch [90/200], Loss: 0.0418\n",
      "Epoch [91/200], Loss: 0.0612\n",
      "Epoch [92/200], Loss: 0.0397\n",
      "Epoch [93/200], Loss: 0.0414\n",
      "Epoch [94/200], Loss: 0.0517\n",
      "Epoch [95/200], Loss: 0.0485\n",
      "Epoch [96/200], Loss: 0.0526\n",
      "Epoch [97/200], Loss: 0.0584\n",
      "Epoch [98/200], Loss: 0.0483\n",
      "Epoch [99/200], Loss: 0.0398\n",
      "Epoch [100/200], Loss: 0.0397\n",
      "Epoch [101/200], Loss: 0.0360\n",
      "Epoch [102/200], Loss: 0.0483\n",
      "Epoch [103/200], Loss: 0.0435\n",
      "Epoch [104/200], Loss: 0.0405\n",
      "Epoch [105/200], Loss: 0.0463\n",
      "Epoch [106/200], Loss: 0.0463\n",
      "Epoch [107/200], Loss: 0.0580\n",
      "Epoch [108/200], Loss: 0.0487\n",
      "Epoch [109/200], Loss: 0.0537\n",
      "Epoch [110/200], Loss: 0.0555\n",
      "Epoch [111/200], Loss: 0.0474\n",
      "Epoch [112/200], Loss: 0.0590\n",
      "Epoch [113/200], Loss: 0.0383\n",
      "Epoch [114/200], Loss: 0.0464\n",
      "Epoch [115/200], Loss: 0.0424\n",
      "Epoch [116/200], Loss: 0.0455\n",
      "Epoch [117/200], Loss: 0.0518\n",
      "Epoch [118/200], Loss: 0.0539\n",
      "Epoch [119/200], Loss: 0.0628\n",
      "Epoch [120/200], Loss: 0.0632\n",
      "Early stopping at epoch 121\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        data = data.to(device)\n",
    "        label = data.y.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output.squeeze(), label)\n",
    "\n",
    "        # backward pass and optimization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # AI 说这里加一个梯度裁剪\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    scheduler.step(avg_loss)  # 根据当前损失调整学习率\n",
    "    early_stopping(avg_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d29ec",
   "metadata": {},
   "source": [
    "# step 4: Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30490b1",
   "metadata": {},
   "source": [
    "这个评估指标是agent写的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbd504f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试集评估:\n",
      "  MAE:   53.2463\n",
      "  RMSE: 92.6498\n",
      "  R²:   0.9625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def test(model, loader, dataset, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # 反归一化\n",
    "            if hasattr(dataset, 'dataset'):\n",
    "                label_mean = dataset.dataset.label_mean\n",
    "                label_std = dataset.dataset.label_std\n",
    "            else:\n",
    "                label_mean = dataset.label_mean\n",
    "                label_std = dataset.label_std\n",
    "            output = output * label_std + label_mean\n",
    "            target = data.y * label_std + label_mean\n",
    "            \n",
    "            predictions.extend(output.cpu().numpy())\n",
    "            targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions).flatten()\n",
    "    targets = np.array(targets).flatten()\n",
    "    \n",
    "    # 计算评估指标\n",
    "    mae = mean_absolute_error(targets, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(targets, predictions))\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    \n",
    "    print(f\"\\n测试集评估:\")\n",
    "    print(f\"  MAE:   {mae:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    \n",
    "    return predictions, targets\n",
    "\n",
    "# 使用\n",
    "predictions, targets = test(model, test_loader, test_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2a1ebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 642.8277],\n",
      "        [ 525.6906],\n",
      "        [ 309.9766],\n",
      "        [ 221.5903],\n",
      "        [ 794.6644],\n",
      "        [1743.1216],\n",
      "        [ 813.2318],\n",
      "        [ 694.8705],\n",
      "        [ 226.4801],\n",
      "        [1288.0330],\n",
      "        [1594.4539],\n",
      "        [ 623.2313],\n",
      "        [ 633.3937],\n",
      "        [ 291.9004],\n",
      "        [ 681.1582],\n",
      "        [ 592.4925],\n",
      "        [ 449.8996],\n",
      "        [ 455.0058],\n",
      "        [ 226.3767],\n",
      "        [ 740.4271],\n",
      "        [ 192.4677],\n",
      "        [ 371.3585],\n",
      "        [ 263.1004],\n",
      "        [ 461.0519],\n",
      "        [ 313.2459],\n",
      "        [ 443.3501],\n",
      "        [ 939.6577],\n",
      "        [ 723.4598],\n",
      "        [ 570.8029],\n",
      "        [ 647.4584],\n",
      "        [ 316.5052],\n",
      "        [1195.9561]], device='cuda:0')\n",
      "tensor([[ 235.4214],\n",
      "        [ 210.3370],\n",
      "        [ 430.1396],\n",
      "        [ 219.9712],\n",
      "        [ 350.2084],\n",
      "        [ 195.5072],\n",
      "        [ 246.6930],\n",
      "        [ 821.3751],\n",
      "        [ 492.9871],\n",
      "        [ 578.8225],\n",
      "        [ 630.8176],\n",
      "        [ 331.5377],\n",
      "        [ 146.9274],\n",
      "        [ 243.4542],\n",
      "        [ 294.1921],\n",
      "        [ 332.7648],\n",
      "        [ 333.9263],\n",
      "        [ 284.3738],\n",
      "        [ 170.0855],\n",
      "        [ 313.7606],\n",
      "        [ 644.5001],\n",
      "        [1089.8722],\n",
      "        [1415.2300],\n",
      "        [ 316.7334],\n",
      "        [ 450.4001],\n",
      "        [ 530.2423],\n",
      "        [1371.8735],\n",
      "        [1214.6987],\n",
      "        [ 523.0782],\n",
      "        [1175.0096],\n",
      "        [ 747.4453],\n",
      "        [ 548.1779]], device='cuda:0')\n",
      "tensor([[ 345.4873],\n",
      "        [1049.6603],\n",
      "        [ 991.1425],\n",
      "        [ 648.4797],\n",
      "        [ 579.5952],\n",
      "        [ 984.1056],\n",
      "        [ 791.1215],\n",
      "        [ 181.1203],\n",
      "        [ 195.3500],\n",
      "        [ 184.6782],\n",
      "        [ 310.7756],\n",
      "        [ 180.7582],\n",
      "        [ 181.1747],\n",
      "        [ 455.3719],\n",
      "        [ 212.7257],\n",
      "        [ 249.8475],\n",
      "        [ 327.9993],\n",
      "        [ 649.2991],\n",
      "        [ 426.5434],\n",
      "        [ 631.8810],\n",
      "        [ 179.4728],\n",
      "        [ 352.3725],\n",
      "        [ 460.4797],\n",
      "        [ 101.0662],\n",
      "        [ 801.7179],\n",
      "        [ 637.4318],\n",
      "        [ 712.4198],\n",
      "        [ 158.1789],\n",
      "        [ 259.2546],\n",
      "        [ 719.0232],\n",
      "        [ 548.3538],\n",
      "        [ 475.8639]], device='cuda:0')\n",
      "tensor([[ 589.8905],\n",
      "        [ 367.7001],\n",
      "        [1335.7083],\n",
      "        [ 420.5112],\n",
      "        [ 532.7274],\n",
      "        [ 186.3925],\n",
      "        [ 644.2940],\n",
      "        [ 503.6823],\n",
      "        [ 108.0128],\n",
      "        [ 753.2177],\n",
      "        [ 279.7229],\n",
      "        [ 377.0221],\n",
      "        [3483.4351],\n",
      "        [ 623.9537],\n",
      "        [ 588.4470],\n",
      "        [ 242.5523],\n",
      "        [ 873.4871],\n",
      "        [ 643.4354],\n",
      "        [3512.4629],\n",
      "        [ 408.4653],\n",
      "        [ 484.3837],\n",
      "        [ 325.2441],\n",
      "        [ 422.3069],\n",
      "        [ 339.8251],\n",
      "        [ 185.0296],\n",
      "        [ 497.5201],\n",
      "        [ 385.6882],\n",
      "        [ 286.6970],\n",
      "        [ 581.9263],\n",
      "        [ 207.6066],\n",
      "        [ 329.5607],\n",
      "        [ 273.8392]], device='cuda:0')\n",
      "tensor([[ 611.9384],\n",
      "        [ 209.1903],\n",
      "        [ 374.6179],\n",
      "        [ 409.6136],\n",
      "        [ 529.0446],\n",
      "        [ 264.2162],\n",
      "        [1309.2135],\n",
      "        [ 741.0082],\n",
      "        [ 367.3369],\n",
      "        [ 371.1077],\n",
      "        [ 221.4944],\n",
      "        [ 329.1063],\n",
      "        [ 416.0837],\n",
      "        [ 272.0564],\n",
      "        [1000.5948],\n",
      "        [ 247.1046],\n",
      "        [ 217.7516],\n",
      "        [ 568.3582],\n",
      "        [ 266.4970],\n",
      "        [ 245.7848],\n",
      "        [1145.9124],\n",
      "        [ 422.8415],\n",
      "        [ 417.3521],\n",
      "        [ 699.7158],\n",
      "        [ 650.0771],\n",
      "        [ 151.7242],\n",
      "        [ 229.1314],\n",
      "        [ 198.8874],\n",
      "        [ 430.9895],\n",
      "        [ 324.6554],\n",
      "        [ 322.1181],\n",
      "        [1082.8960]], device='cuda:0')\n",
      "tensor([[ 433.1422],\n",
      "        [ 787.2862],\n",
      "        [ 400.6968],\n",
      "        [ 334.2059],\n",
      "        [ 620.2473],\n",
      "        [ 625.4298],\n",
      "        [1463.2466],\n",
      "        [ 741.3307],\n",
      "        [ 218.9792],\n",
      "        [1133.2462],\n",
      "        [ 596.5013],\n",
      "        [ 287.5908],\n",
      "        [ 485.3473],\n",
      "        [ 488.7940],\n",
      "        [ 443.5827],\n",
      "        [ 284.7791],\n",
      "        [ 270.8378],\n",
      "        [3357.0994],\n",
      "        [ 496.9103],\n",
      "        [ 771.9070],\n",
      "        [ 400.8055],\n",
      "        [ 602.2587],\n",
      "        [ 253.4211],\n",
      "        [ 476.5382],\n",
      "        [ 315.7531],\n",
      "        [ 523.1942],\n",
      "        [ 341.1786],\n",
      "        [ 527.0068],\n",
      "        [ 205.8551],\n",
      "        [ 252.6411],\n",
      "        [ 293.8076],\n",
      "        [ 161.6807]], device='cuda:0')\n",
      "tensor([[ 767.7658],\n",
      "        [ 270.5076],\n",
      "        [ 573.0618],\n",
      "        [ 381.4067],\n",
      "        [ 189.4607],\n",
      "        [ 493.5254],\n",
      "        [ 396.1607],\n",
      "        [1211.0197],\n",
      "        [ 585.9076],\n",
      "        [ 565.8558],\n",
      "        [ 284.9311],\n",
      "        [ 311.1837],\n",
      "        [2107.5476],\n",
      "        [ 252.4330],\n",
      "        [ 908.5961],\n",
      "        [ 296.6447],\n",
      "        [ 647.6285],\n",
      "        [ 511.5059],\n",
      "        [ 261.4598],\n",
      "        [ 675.8387],\n",
      "        [ 221.4398],\n",
      "        [ 383.6007],\n",
      "        [1543.5828],\n",
      "        [ 346.3358],\n",
      "        [ 199.3029],\n",
      "        [ 701.3932],\n",
      "        [ 530.4232],\n",
      "        [ 233.8790],\n",
      "        [ 316.2595],\n",
      "        [ 599.8200],\n",
      "        [ 492.4030],\n",
      "        [ 772.2498]], device='cuda:0')\n",
      "tensor([[ 174.6803],\n",
      "        [ 746.7336],\n",
      "        [ 431.7157],\n",
      "        [ 294.4576],\n",
      "        [ 721.2372],\n",
      "        [ 248.1478],\n",
      "        [ 319.6132],\n",
      "        [ 608.6184],\n",
      "        [ 561.8449],\n",
      "        [ 400.4565],\n",
      "        [ 630.7201],\n",
      "        [ 289.6232],\n",
      "        [1169.6985],\n",
      "        [ 122.5606],\n",
      "        [ 494.5214],\n",
      "        [ 233.0177],\n",
      "        [ 714.0962],\n",
      "        [ 477.5999],\n",
      "        [ 642.7839],\n",
      "        [ 245.7261],\n",
      "        [ 183.0855],\n",
      "        [ 791.3008],\n",
      "        [ 491.4522],\n",
      "        [ 385.1296],\n",
      "        [ 355.5477],\n",
      "        [1970.9170],\n",
      "        [ 435.2297],\n",
      "        [1305.8901],\n",
      "        [1144.0031]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        output = output * full_data.label_std + full_data.label_mean\n",
    "        print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.7.0",
   "language": "python",
   "name": "pytorch-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
