{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8216f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 5090\n",
      "Memory Allocated: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Memory Allocated:\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9178d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch. utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from pymatgen.io.cif import CifParser\n",
    "from pymatgen.core import Structure, Element\n",
    "\n",
    "group_number = 18\n",
    "row_number = 7\n",
    "X_class_number = 10\n",
    "r_class_number = 10\n",
    "node_dim = group_number + row_number + X_class_number + r_class_number\n",
    "\n",
    "distance_class_number = 10\n",
    "edge_dim = distance_class_number\n",
    "\n",
    "learned_dim = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6f13a",
   "metadata": {},
   "source": [
    "# Step 1 Data Preparation\n",
    "\n",
    "- Use pymatgen to load the json_gz file and pretty print the content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9726defb",
   "metadata": {},
   "source": [
    "\n",
    "## dataset\n",
    "\n",
    "- Input matrix should contains information about nodes and edges.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093e50ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor([-0.9775])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "path = './matbench_phonons.json/phonons.json'\n",
    "\n",
    "class DataTransform(Dataset):\n",
    "    def __init__(self, path, normalize = True):\n",
    "        super().__init__()\n",
    "        with open(path) as f:\n",
    "            obj = json.load(f)\n",
    "        self.index = obj[\"index\"]\n",
    "        self.data = obj[\"data\"]\n",
    "        max_index = max(self.index) + 1 if self.index else 0\n",
    "        self.struct_list = [None] * max_index    \n",
    "        for idx, data_item in zip(self.index, self.data):\n",
    "            self.struct_list[idx] = Structure.from_dict(data_item[0])\n",
    "        \n",
    "        self.normalize = normalize\n",
    "        if self.normalize:\n",
    "            all_labels = [self.data[idx][1] for idx in self.index]\n",
    "            self.label_mean = np.mean(all_labels)\n",
    "            self.label_std = np.std(all_labels)\n",
    "        else:\n",
    "            self.label_mean = 0.0\n",
    "            self.label_std = 1.0\n",
    "\n",
    "    def __len__(self):  # 必须实现\n",
    "        return len(self.index)\n",
    "    \n",
    "    def build_node(self, idx):\n",
    "        struct = self.struct_list[idx]\n",
    "        tensor_list = []\n",
    "        for site in struct.sites:\n",
    "            element = Element(site.specie.symbol)\n",
    "            radius = element.atomic_radius * 100  # convert to pm\n",
    "            # OneHot encoding with group and row:\n",
    "            group = element.group\n",
    "            row = element.row\n",
    "            X = element.X\n",
    "            # OneHot encoding with group and row:\n",
    "            group = F.one_hot(torch.tensor(group - 1), num_classes=18).float()\n",
    "            row = F.one_hot(torch.tensor(row - 1), num_classes=7).float()\n",
    "            if(25<=radius<250):\n",
    "                radius = F.one_hot(torch.tensor(int((radius - 25)/22.5)), num_classes=10).float()\n",
    "            else:\n",
    "                radius = torch.zeros(10)\n",
    "            if (X < 0.5 or X >= 4.0):\n",
    "                X =torch.zeros(10)\n",
    "            else:\n",
    "                X = F.one_hot(torch.tensor(int((X - 0.5) / 0.35)), num_classes=10).float()\n",
    "            # concate group and row features\n",
    "            node_feat = torch.cat([group, row, X, radius], dim=0)\n",
    "            # print(node_feats): \n",
    "            # tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # group 8\n",
    "            #         0, 0, 1, 0, 0, 0, 0,        # row 3\n",
    "            #         0, 0, 0, 0, 1, 0, 0, 0, 0, 0])          # X\n",
    "            \n",
    "            # concate group and row features \n",
    "            \n",
    "            tensor_list.append(node_feat)\n",
    "        node_feats = torch.stack(tensor_list, dim=0)\n",
    "        return node_feats\n",
    "    \n",
    "    def build_edge(self, idx, cutoff=5.0):\n",
    "        struct = self.struct_list[idx]\n",
    "        num_atoms = len(struct.sites)\n",
    "        nbrs = struct.get_all_neighbors(cutoff)\n",
    "        tensor_list = []\n",
    "        edge_index = torch.zeros((2,0), dtype=torch.long)\n",
    "        for center_idx, neighbors in enumerate(nbrs):\n",
    "            for neighbor in neighbors:\n",
    "                distance = neighbor.nn_distance\n",
    "                if (distance < 0.7 or distance >= 5.2):\n",
    "                    distance = torch.zeros(10)\n",
    "                else:\n",
    "                    distance = F.one_hot(torch.tensor(int((distance-0.7)/0.45)), num_classes=10).float()\n",
    "                tensor_list.append((distance))\n",
    "                edge_index = torch.cat([edge_index, torch.tensor([[center_idx],[neighbor.index]])], dim=1)\n",
    "            \n",
    "        edge_fea = torch.stack(tensor_list, dim=0)\n",
    "        return edge_index, edge_fea\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        node_fea = self.build_node(idx)\n",
    "        edge_index, edge_fea = self.build_edge(idx)\n",
    "        label = self.data[idx][1]\n",
    "        if self.normalize:\n",
    "            label = (label - self.label_mean) / self.label_std\n",
    "        y = torch.tensor([label], dtype=torch.float32)\n",
    "        data = Data(\n",
    "            x=node_fea,      \n",
    "            edge_index=edge_index, \n",
    "            edge_attr=edge_fea,\n",
    "            y=y\n",
    "        )\n",
    "        return data\n",
    "    \n",
    "'''    \n",
    "    def build_visualized_graph(self, idx, cutoff=5.0):\n",
    "        struct = self.struct_list[idx]\n",
    "        num_atoms = len(struct.sites)\n",
    "        G = nx.Graph()\n",
    "        for i in range(num_atoms):\n",
    "            G.add_node(i, element=struct.sites[i].specie.symbol)\n",
    "        nbrs = struct.get_all_neighbors(cutoff)\n",
    "        for center_idx, neighbors in enumerate(nbrs):\n",
    "            for neighbor in neighbors:\n",
    "                neighbor_idx = neighbor.index\n",
    "                if not G.has_edge(center_idx, neighbor_idx):\n",
    "                   G.add_edge(center_idx, neighbor_idx, distance=neighbor.nn_distance)\n",
    "        return G\n",
    "'''    \n",
    "\n",
    "try:\n",
    "    tryone = DataTransform(path)\n",
    "    \n",
    "    x, edge_index, edge_attr, y = tryone[0].x, tryone[0].edge_index, tryone[0].edge_attr, tryone[0].y\n",
    "    print(x)\n",
    "    print(edge_index)\n",
    "    print(edge_attr)\n",
    "    print(y)\n",
    "except Exception as e:\n",
    "    print(f\"运行出错：{e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fec9a",
   "metadata": {},
   "source": [
    "## Train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee4b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_data = DataTransform(path)\n",
    "\n",
    "train_size = int(0.8 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(\n",
    "    full_data, \n",
    "    [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # 固定随机种子\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03acb4",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3499267",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdecfd99",
   "metadata": {},
   "source": [
    "# Step 2- Build CGCNN model using PyTorch Geometric\n",
    "- Use CGCNNLayer from the paper to build the model\n",
    "- Use DataTransform class to transform the data into PyG format\n",
    "- The formulation of CGCNNLayer is as follows:\n",
    "$$ v_i^{(t+1)}​ = v_i^{(t)} ​+ \\sum_{j,k} ​σ(z_{(i,j)_{k}}​^{(t)} ​W_f^{(t)} ​+ b_f^{(t)} ​) \\odot g(z_{(i,j)_{k}}​^{(t)} ​W_s{(t)}​ + b_s^{(t)}​)$$\n",
    "- Use propagate function from PyG to implement the message passing mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a43718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGCNNLayer(MessagePassing):\n",
    "    def __init__(\n",
    "            self, \n",
    "            node_dim, \n",
    "            edge_dim, \n",
    "        ):\n",
    "        super(CGCNNLayer, self).__init__(aggr = 'add')\n",
    "        self.l1 = nn.Linear(2 * node_dim + edge_dim, node_dim)\n",
    "        self.l2 = nn.Linear(2 * node_dim + edge_dim, node_dim)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        z = torch.cat([x_i, x_j, edge_attr], dim=1)\n",
    "        # attention mechanism\n",
    "        att = torch.sigmoid(self.l1(z))\n",
    "        # feature transformation\n",
    "        feat = F.relu(self.l2(z))\n",
    "        # element-wise multiplication: attention * feature\n",
    "        z = att * feat\n",
    "        return z    \n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        \"\"\"aggr_out: adjacent node output; x: node_fea\"\"\"\n",
    "        v = x + aggr_out\n",
    "        \n",
    "        return v\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea2e6f",
   "metadata": {},
   "source": [
    "# Step 3: Model construction\n",
    "\n",
    "- Build the CGCNN model using multiple CGCNNLayer layers\n",
    "- Number of layers:\n",
    "- - GCNNNLayer: 2\n",
    "- - Fully connected layers: 2\n",
    "- - Pooling layer: global mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90758b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 node_input_dim = node_dim,\n",
    "                 edge_input_dim = edge_dim,\n",
    "                 hidden_dim = 64,\n",
    "                 num_conv_layers = 4,\n",
    "                 dropout = 0.1\n",
    "                 ):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.node_embedding = nn.Sequential(\n",
    "            nn.Linear(node_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.edge_embedding = nn.Sequential(\n",
    "            nn.Linear(edge_input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            CGCNNLayer(hidden_dim, hidden_dim) \n",
    "            for _ in range(num_conv_layers)\n",
    "        ])\n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(hidden_dim) \n",
    "            for _ in range(num_conv_layers)\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        batch = data.batch  \n",
    "        x = self.node_embedding(x)\n",
    "        edge_attr = self.edge_embedding(edge_attr)\n",
    "        for conv, bn in zip(self.conv_layers, self.batch_norms):\n",
    "            identity = x\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = x + identity \n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Output Layer\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65783ccf",
   "metadata": {},
   "source": [
    "# Step 4 : Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56ad1e",
   "metadata": {},
   "source": [
    "## Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81fade61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在使用的设备: cuda\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"正在使用的设备: {device}\")\n",
    "model = model.to(device) \n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "criterion = criterion.to(device)  \n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b92440d",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "AI 加的，早停，减少跑过量的epochs的耗费时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad68741",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=20, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0bd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.6269\n",
      "Epoch [2/200], Loss: 0.4314\n",
      "Epoch [3/200], Loss: 0.3382\n",
      "Epoch [4/200], Loss: 0.2923\n",
      "Epoch [5/200], Loss: 0.2468\n",
      "Epoch [6/200], Loss: 0.2838\n",
      "Epoch [7/200], Loss: 0.2382\n",
      "Epoch [8/200], Loss: 0.2178\n",
      "Epoch [9/200], Loss: 0.2297\n",
      "Epoch [10/200], Loss: 0.2055\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        data = data.to(device)\n",
    "        label = data.y.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output.squeeze(), label)\n",
    "\n",
    "        # backward pass and optimization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # AI 说这里加一个梯度裁剪\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    scheduler.step(avg_loss)  # 根据当前损失调整学习率\n",
    "    early_stopping(avg_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d29ec",
   "metadata": {},
   "source": [
    "# step 5: Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30490b1",
   "metadata": {},
   "source": [
    "这个评估指标是agent写的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd504f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions, targets\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 使用\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m predictions, targets = test(\u001b[43mmodel\u001b[49m, test_loader, test_data, device)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def test(model, loader, dataset, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # 反归一化\n",
    "            if hasattr(dataset, 'dataset'):\n",
    "                label_mean = dataset.dataset.label_mean\n",
    "                label_std = dataset.dataset.label_std\n",
    "            else:\n",
    "                label_mean = dataset.label_mean\n",
    "                label_std = dataset.label_std\n",
    "            output = output * label_std + label_mean\n",
    "            target = data.y * label_std + label_mean\n",
    "            \n",
    "            predictions.extend(output.cpu().numpy())\n",
    "            targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions).flatten()\n",
    "    targets = np.array(targets).flatten()\n",
    "    \n",
    "    # 计算评估指标\n",
    "    mae = mean_absolute_error(targets, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(targets, predictions))\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    \n",
    "    print(f\"\\n测试集评估:\")\n",
    "    print(f\"  MAE:   {mae:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    \n",
    "    return predictions, targets\n",
    "\n",
    "# 使用\n",
    "predictions, targets = test(model, test_loader, test_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1ebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 541.4744],\n",
      "        [ 454.8799],\n",
      "        [ 264.2036],\n",
      "        [ 197.3368],\n",
      "        [ 723.0032],\n",
      "        [1981.9058],\n",
      "        [1299.3427],\n",
      "        [ 709.2236],\n",
      "        [ 188.1557],\n",
      "        [1028.1255],\n",
      "        [1494.8818],\n",
      "        [ 583.8770],\n",
      "        [ 561.4660],\n",
      "        [ 262.1461],\n",
      "        [ 638.2465],\n",
      "        [ 548.0864],\n",
      "        [ 368.1105],\n",
      "        [ 472.6346],\n",
      "        [ 224.9679],\n",
      "        [ 685.4538],\n",
      "        [ 195.8480],\n",
      "        [ 361.9217],\n",
      "        [ 231.2910],\n",
      "        [ 456.8365],\n",
      "        [ 320.1815],\n",
      "        [ 475.6884],\n",
      "        [ 959.0400],\n",
      "        [ 636.2151],\n",
      "        [ 503.5185],\n",
      "        [ 636.9849],\n",
      "        [ 335.1805],\n",
      "        [1207.1873]], device='cuda:0')\n",
      "tensor([[ 236.8115],\n",
      "        [ 193.1265],\n",
      "        [ 425.6162],\n",
      "        [ 226.0678],\n",
      "        [ 358.5158],\n",
      "        [ 166.6327],\n",
      "        [ 275.1517],\n",
      "        [ 858.1161],\n",
      "        [ 508.5836],\n",
      "        [ 532.3908],\n",
      "        [ 577.4448],\n",
      "        [ 302.4720],\n",
      "        [ 156.2754],\n",
      "        [ 266.1908],\n",
      "        [ 283.0606],\n",
      "        [ 342.1016],\n",
      "        [ 306.3455],\n",
      "        [ 356.7887],\n",
      "        [ 165.1133],\n",
      "        [ 227.2773],\n",
      "        [ 674.0826],\n",
      "        [1062.1909],\n",
      "        [1367.1882],\n",
      "        [ 285.8445],\n",
      "        [ 452.0622],\n",
      "        [ 531.6799],\n",
      "        [1398.6429],\n",
      "        [1191.0122],\n",
      "        [ 506.4348],\n",
      "        [1169.1995],\n",
      "        [ 722.0392],\n",
      "        [ 557.1678]], device='cuda:0')\n",
      "tensor([[ 350.6314],\n",
      "        [1107.9524],\n",
      "        [ 842.4294],\n",
      "        [ 534.8119],\n",
      "        [ 533.1102],\n",
      "        [ 932.9305],\n",
      "        [ 710.5998],\n",
      "        [ 215.3470],\n",
      "        [ 191.6017],\n",
      "        [ 191.9065],\n",
      "        [ 229.9387],\n",
      "        [ 199.4918],\n",
      "        [ 198.2292],\n",
      "        [ 474.9150],\n",
      "        [ 195.7766],\n",
      "        [ 241.7084],\n",
      "        [ 226.2731],\n",
      "        [ 598.2064],\n",
      "        [ 395.0623],\n",
      "        [ 611.1262],\n",
      "        [ 174.4040],\n",
      "        [ 374.4588],\n",
      "        [ 372.0865],\n",
      "        [ 125.7884],\n",
      "        [ 808.6571],\n",
      "        [ 567.1129],\n",
      "        [ 667.3496],\n",
      "        [ 174.8080],\n",
      "        [ 257.9490],\n",
      "        [ 690.2693],\n",
      "        [ 579.0289],\n",
      "        [ 448.0332]], device='cuda:0')\n",
      "tensor([[ 572.6145],\n",
      "        [ 320.0193],\n",
      "        [1179.5974],\n",
      "        [ 392.4462],\n",
      "        [ 445.2394],\n",
      "        [ 192.3940],\n",
      "        [ 654.2327],\n",
      "        [ 487.5435],\n",
      "        [ 186.3645],\n",
      "        [ 664.3422],\n",
      "        [ 282.7702],\n",
      "        [ 393.4846],\n",
      "        [3377.5173],\n",
      "        [ 590.8754],\n",
      "        [ 527.2264],\n",
      "        [ 246.7592],\n",
      "        [ 831.8977],\n",
      "        [ 562.4171],\n",
      "        [6427.2456],\n",
      "        [ 413.9512],\n",
      "        [ 448.4223],\n",
      "        [ 255.2184],\n",
      "        [ 330.3207],\n",
      "        [ 326.6169],\n",
      "        [ 177.5973],\n",
      "        [ 445.2495],\n",
      "        [ 357.2733],\n",
      "        [ 280.0117],\n",
      "        [ 505.8024],\n",
      "        [ 201.2202],\n",
      "        [ 336.3209],\n",
      "        [ 225.0276]], device='cuda:0')\n",
      "tensor([[ 535.1975],\n",
      "        [ 192.1715],\n",
      "        [ 351.8708],\n",
      "        [ 375.5097],\n",
      "        [ 453.7479],\n",
      "        [ 207.3452],\n",
      "        [1354.7856],\n",
      "        [ 760.9530],\n",
      "        [ 376.1372],\n",
      "        [ 370.6949],\n",
      "        [ 203.4217],\n",
      "        [ 224.1867],\n",
      "        [ 269.8026],\n",
      "        [ 260.1866],\n",
      "        [1140.8954],\n",
      "        [ 219.0178],\n",
      "        [ 211.7164],\n",
      "        [ 513.6769],\n",
      "        [ 241.6474],\n",
      "        [ 216.3021],\n",
      "        [ 981.5414],\n",
      "        [ 423.0659],\n",
      "        [ 385.8322],\n",
      "        [ 691.4940],\n",
      "        [ 595.9907],\n",
      "        [ 202.1071],\n",
      "        [ 214.9848],\n",
      "        [ 188.9431],\n",
      "        [ 374.5584],\n",
      "        [ 306.2907],\n",
      "        [ 300.6268],\n",
      "        [1263.6768]], device='cuda:0')\n",
      "tensor([[ 417.9994],\n",
      "        [ 813.6531],\n",
      "        [ 372.1779],\n",
      "        [ 287.0654],\n",
      "        [ 538.3478],\n",
      "        [ 598.5121],\n",
      "        [1621.1155],\n",
      "        [ 699.9119],\n",
      "        [ 264.6748],\n",
      "        [1112.8525],\n",
      "        [ 535.3406],\n",
      "        [ 291.0396],\n",
      "        [ 424.6473],\n",
      "        [ 438.6539],\n",
      "        [ 436.8553],\n",
      "        [ 325.7839],\n",
      "        [ 257.9988],\n",
      "        [4495.8843],\n",
      "        [ 395.4743],\n",
      "        [ 632.4061],\n",
      "        [ 374.5211],\n",
      "        [ 578.5101],\n",
      "        [ 223.6260],\n",
      "        [ 513.6947],\n",
      "        [ 307.0954],\n",
      "        [ 422.0402],\n",
      "        [ 301.4397],\n",
      "        [ 576.0036],\n",
      "        [ 218.9346],\n",
      "        [ 259.7798],\n",
      "        [ 350.4310],\n",
      "        [ 180.7760]], device='cuda:0')\n",
      "tensor([[ 751.6376],\n",
      "        [ 280.5286],\n",
      "        [ 517.5050],\n",
      "        [ 427.1270],\n",
      "        [ 205.9987],\n",
      "        [ 495.7955],\n",
      "        [ 291.8896],\n",
      "        [1115.0208],\n",
      "        [ 524.4844],\n",
      "        [ 543.1277],\n",
      "        [ 279.9711],\n",
      "        [ 334.9653],\n",
      "        [1961.6050],\n",
      "        [ 237.6938],\n",
      "        [ 833.7877],\n",
      "        [ 228.3943],\n",
      "        [ 642.3041],\n",
      "        [ 453.3837],\n",
      "        [ 266.7671],\n",
      "        [ 656.2536],\n",
      "        [ 194.9702],\n",
      "        [ 291.1164],\n",
      "        [1514.8300],\n",
      "        [ 369.1938],\n",
      "        [ 217.3024],\n",
      "        [ 627.1093],\n",
      "        [ 377.0934],\n",
      "        [ 194.7481],\n",
      "        [ 310.2883],\n",
      "        [ 575.3781],\n",
      "        [ 446.9496],\n",
      "        [ 897.2499]], device='cuda:0')\n",
      "tensor([[ 237.8123],\n",
      "        [ 671.4567],\n",
      "        [ 453.5271],\n",
      "        [ 285.1543],\n",
      "        [ 752.2014],\n",
      "        [ 271.8838],\n",
      "        [ 336.6339],\n",
      "        [ 561.7067],\n",
      "        [ 515.9097],\n",
      "        [ 355.1589],\n",
      "        [ 553.3389],\n",
      "        [ 275.3547],\n",
      "        [1220.9719],\n",
      "        [ 177.6958],\n",
      "        [ 432.6173],\n",
      "        [ 277.5008],\n",
      "        [ 689.6792],\n",
      "        [ 477.0232],\n",
      "        [ 607.8235],\n",
      "        [ 241.1037],\n",
      "        [ 185.1673],\n",
      "        [ 679.9305],\n",
      "        [ 463.1911],\n",
      "        [ 396.2594],\n",
      "        [ 349.6995],\n",
      "        [2310.8372],\n",
      "        [ 345.9216],\n",
      "        [1453.7529],\n",
      "        [1071.6841]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        output = output * full_data.label_std + full_data.label_mean\n",
    "        print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.7.0",
   "language": "python",
   "name": "pytorch-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
